{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQGCjWYaAeDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6eb034-e6be-4877-cdfc-d69d25e203a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "6R8zlrh3AmJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "TytjO1-YA-BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing CSV's\n",
        "\n",
        "changes = pd.read_csv(\"/content/drive/MyDrive/College/ML Sem 6/Assignment 2/changes-visitors-covid_final.csv\")\n",
        "covid = pd.read_csv(\"/content/drive/MyDrive/College/ML Sem 6/Assignment 2/covid-data.csv\")"
      ],
      "metadata": {
        "id": "GS3TwfWsAn0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making necessary changes in the CSV's\n",
        "\n",
        "changes = changes[changes['Entity']=='India']\n",
        "changes.rename(columns={\"Day\":\"date\",\"Code\":\"iso_code\",\"Entity\":\"location\"},inplace=True)\n",
        "\n",
        "covid = covid[[\"iso_code\",\"continent\",\"location\",\"date\",\"new_cases\"]]\n",
        "covid = covid[covid['location'] == 'India']"
      ],
      "metadata": {
        "id": "g3AFS7VrAumI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5d0a02-7dfe-43a8-83ef-5860ccb6b622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c38ee2f018dc>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  changes.rename(columns={\"Day\":\"date\",\"Code\":\"iso_code\",\"Entity\":\"location\"},inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the datasets using date criteria\n",
        "df = pd.merge(changes, covid, on = ['date','location',\"iso_code\"])"
      ],
      "metadata": {
        "id": "bES8batcA4LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the atrributes : date, iso_code, continent and location are irrelevent we can drop these columns\n",
        "df = df[[\"retail_and_recreation\",\"grocery_and_pharmacy\",\"residential\",\"transit_stations\",\"parks\",\"workplaces\",\"new_cases\"]]"
      ],
      "metadata": {
        "id": "09glDsPXBFSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping NULL values\n",
        "df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1nozqNqlhpxX",
        "outputId": "282ce5f0-59f2-4a65-896e-4b3f075cfacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     retail_and_recreation  grocery_and_pharmacy  residential  \\\n",
              "0                    0.667                 1.667        0.000   \n",
              "1                    0.500                 1.750        0.000   \n",
              "2                    0.400                 1.800        0.200   \n",
              "3                    0.500                 2.000        0.000   \n",
              "4                   -0.143                 1.714        0.714   \n",
              "..                     ...                   ...          ...   \n",
              "466                -61.714               -25.000       24.143   \n",
              "467                -61.286               -24.429       23.714   \n",
              "468                -61.143               -24.714       23.714   \n",
              "469                -60.143               -23.429       23.286   \n",
              "470                -58.714               -21.143       22.714   \n",
              "\n",
              "     transit_stations   parks  workplaces  new_cases  \n",
              "0               2.000   3.000       3.000        0.0  \n",
              "1               2.000   3.250       3.000        0.0  \n",
              "2               1.800   2.800       3.200        0.0  \n",
              "3               2.333   3.167       3.333        0.0  \n",
              "4               1.429   3.571       0.143        0.0  \n",
              "..                ...     ...         ...        ...  \n",
              "466           -49.143 -41.000     -45.429   173790.0  \n",
              "467           -48.714 -40.000     -44.571   165553.0  \n",
              "468           -49.000 -39.143     -44.286   152734.0  \n",
              "469           -48.286 -38.000     -43.429   127510.0  \n",
              "470           -47.000 -36.571     -42.429   132788.0  \n",
              "\n",
              "[471 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd57edb6-ce87-4bec-9931-f42bce04012e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>retail_and_recreation</th>\n",
              "      <th>grocery_and_pharmacy</th>\n",
              "      <th>residential</th>\n",
              "      <th>transit_stations</th>\n",
              "      <th>parks</th>\n",
              "      <th>workplaces</th>\n",
              "      <th>new_cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.667</td>\n",
              "      <td>1.667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.400</td>\n",
              "      <td>1.800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1.800</td>\n",
              "      <td>2.800</td>\n",
              "      <td>3.200</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.500</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.333</td>\n",
              "      <td>3.167</td>\n",
              "      <td>3.333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.143</td>\n",
              "      <td>1.714</td>\n",
              "      <td>0.714</td>\n",
              "      <td>1.429</td>\n",
              "      <td>3.571</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>-61.714</td>\n",
              "      <td>-25.000</td>\n",
              "      <td>24.143</td>\n",
              "      <td>-49.143</td>\n",
              "      <td>-41.000</td>\n",
              "      <td>-45.429</td>\n",
              "      <td>173790.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>-61.286</td>\n",
              "      <td>-24.429</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-48.714</td>\n",
              "      <td>-40.000</td>\n",
              "      <td>-44.571</td>\n",
              "      <td>165553.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>-61.143</td>\n",
              "      <td>-24.714</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-49.000</td>\n",
              "      <td>-39.143</td>\n",
              "      <td>-44.286</td>\n",
              "      <td>152734.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>-60.143</td>\n",
              "      <td>-23.429</td>\n",
              "      <td>23.286</td>\n",
              "      <td>-48.286</td>\n",
              "      <td>-38.000</td>\n",
              "      <td>-43.429</td>\n",
              "      <td>127510.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>-58.714</td>\n",
              "      <td>-21.143</td>\n",
              "      <td>22.714</td>\n",
              "      <td>-47.000</td>\n",
              "      <td>-36.571</td>\n",
              "      <td>-42.429</td>\n",
              "      <td>132788.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>471 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd57edb6-ce87-4bec-9931-f42bce04012e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd57edb6-ce87-4bec-9931-f42bce04012e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd57edb6-ce87-4bec-9931-f42bce04012e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions"
      ],
      "metadata": {
        "id": "wYOf85xSBQld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Outliers\n",
        "\n",
        "def remove_outliers(col_name, df):\n",
        "    # print(\"Start\")\n",
        "    Q1 = np.percentile(df[col_name], 25,interpolation = 'midpoint')\n",
        "    # print(Q1)\n",
        "    Q3 = np.percentile(df[col_name], 75,interpolation = 'midpoint')\n",
        "    # print(Q3)\n",
        "    IQR = Q3 - Q1\n",
        "    # print(IQR) \n",
        "    upper = (Q3+1.5*IQR)\n",
        "    # print(upper)\n",
        "    lower = (Q1-1.5*IQR)\n",
        "    # print(lower)\n",
        "\n",
        "    n = len(df)\n",
        "\n",
        "    for x in range(n): \n",
        "        # print(x)\n",
        "        df.loc[df[col_name] < lower,col_name] = np.nan\n",
        "        df.loc[df[col_name] > upper,col_name] = np.nan\n",
        "\n",
        "    # print(\"End\")\n"
      ],
      "metadata": {
        "id": "Illhh07jBYO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Val Test Split\n",
        "\n",
        "# df : dataset\n",
        "# train_size : proportion of instances for training\n",
        "# val_size  : proportion of instances for validation\n",
        "\n",
        "def train_val_test_split(df,train_size,val_size):\n",
        "    # shuffling the rows randomly to avoid uneveness in train.val and test\n",
        "    df = df.sample(frac = 1,random_state=24)\n",
        "\n",
        "    # number of instances\n",
        "    rows = len(df)\n",
        "    train_idx = int(len(df)*train_size)\n",
        "    train = df[0:train_idx]\n",
        "\n",
        "    val_idx = train_idx + int(len(df)*val_size)\n",
        "    val = df[train_idx:val_idx]\n",
        "\n",
        "    test = df[val_idx:]    \n",
        "    \n",
        "    return train,val,test"
      ],
      "metadata": {
        "id": "wT94Lm4rCCjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Decision Tree"
      ],
      "metadata": {
        "id": "a15zUda-B8Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CART\n",
        "\n",
        "def is_numeric(value):\n",
        "  return isinstance(value, int) or isinstance(value, float)\n",
        "\n",
        "def class_counts(rows):\n",
        "  # Counts the unique classes in the dataset\n",
        "  counts = {}\n",
        "\n",
        "  for row in rows:\n",
        "    label = row[-1]\n",
        "    if label not in counts:\n",
        "      counts[label] = 0\n",
        "    \n",
        "    counts[label] += 1\n",
        "\n",
        "  return counts\n",
        "\n",
        "\n",
        "class DecisionNode:\n",
        "  def __init__(self, threshold = None, true_branch = None, false_branch = None):\n",
        "    self.threshold = threshold\n",
        "    self.true_branch = true_branch\n",
        "    self.false_branch = false_branch\n",
        "\n",
        "class DecisionLeafNode:\n",
        "  def __init__(self, predictions):\n",
        "    self.predictions = class_counts(predictions)\n",
        "\n",
        "class Threshold:\n",
        "\n",
        "  def __init__(self, feature, value):\n",
        "    self.feature = feature\n",
        "    self.value = value\n",
        "\n",
        "  def match(self, row):\n",
        "    # Condition to partition given data into two child nodes based on threshold criteria\n",
        "    test_value = row[self.feature]\n",
        "    \n",
        "    if is_numeric(test_value):\n",
        "      return test_value >= self.value\n",
        "    else:\n",
        "      return test_value == self.value\n",
        "\n",
        "\n",
        "  def __repr__(self):\n",
        "      condition = '=='\n",
        "      if is_numeric(self.value):\n",
        "          condition = '>='\n",
        "      return 'Is %s %s %s?' % (\n",
        "          self.feature, condition, str(self.value))\n",
        "\n",
        "class DecisionTree:\n",
        "\n",
        "  def __init__(self, n_features = None, root = None, max_depth = 100):\n",
        "    self.n_features = n_features\n",
        "    \n",
        "    self.root = root\n",
        "    self.max_depth = max_depth\n",
        "\n",
        "\n",
        "  def fit(self, training_data):\n",
        "    self.n_features = len(training_data[0]) - 1\n",
        "    self.root = self._build_tree(training_data)\n",
        "\n",
        "\n",
        "  def _partition(self, training_data, threshold):\n",
        "    # Partitions given node into child nodes using threshold criteria.\n",
        "    true_values = []\n",
        "    false_values = []\n",
        "\n",
        "    for row in training_data:\n",
        "      if type(threshold.value) == type(row[threshold.feature]):\n",
        "        if threshold.match(row):\n",
        "          true_values.append(row)\n",
        "        else:\n",
        "          false_values.append(row)\n",
        "\n",
        "    return true_values, false_values\n",
        "\n",
        "\n",
        "  def _entropy(self, rows):\n",
        "    counts = class_counts(rows)\n",
        "    \n",
        "    result = 0\n",
        "    for lbl in counts:\n",
        "        prob = counts[lbl] / float(len(rows))\n",
        "        result -= prob ** 2\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "  def _information_gain(self, true_values, false_values, parent_entropy):\n",
        "    child_weight = float(len(true_values) / (len(true_values) + len(false_values)))\n",
        "\n",
        "    return parent_entropy - (\n",
        "        child_weight * self._entropy(true_values) + (\n",
        "        1 - child_weight) * self._entropy(false_values))\n",
        "\n",
        "\n",
        "  def _find_best_split(self, training_data):\n",
        "\n",
        "    best_gain = 0\n",
        "    best_threshold = None\n",
        "    parent_entropy = self._entropy(training_data)\n",
        "\n",
        "    # Try every feature as root node, its all classes for thresholding and choose \n",
        "    # the best one using information gain.\n",
        "    for feature in range(self.n_features):\n",
        "      values = set(row[feature] for row in training_data)\n",
        "\n",
        "      for value in values:\n",
        "        if math.isnan(value):\n",
        "          continue\n",
        "\n",
        "        threshold = Threshold(feature, value)\n",
        "\n",
        "        true_values, false_values = self._partition(training_data, threshold)\n",
        "\n",
        "        if len(true_values) == 0 or len(false_values) == 0:\n",
        "          continue\n",
        "\n",
        "        gain = self._information_gain(true_values, false_values, parent_entropy)\n",
        "\n",
        "        if gain >= best_gain:\n",
        "          best_gain, best_threshold = gain, threshold\n",
        "\n",
        "    return best_gain, best_threshold\n",
        "\n",
        "\n",
        "  def _build_tree(self, training_data, depth = 0):\n",
        "\n",
        "      if depth == self.max_depth:\n",
        "        return DecisionLeafNode(training_data)\n",
        "\n",
        "      gain, threshold = self._find_best_split(training_data)\n",
        "\n",
        "      if gain == 0:\n",
        "        return DecisionLeafNode(training_data)\n",
        "    \n",
        "      true_values, false_values = self._partition(training_data, threshold)\n",
        "\n",
        "      # Recursively build left and right subtrees.\n",
        "      true_branch = self._build_tree(true_values, depth + 1)\n",
        "      false_branch = self._build_tree(false_values, depth + 1)\n",
        "\n",
        "      return DecisionNode(threshold, true_branch, false_branch)\n",
        "\n",
        "\n",
        "  def print_tree(self, node = None, spacing = \"\"):\n",
        "    if node is None:\n",
        "      node = self.root\n",
        "\n",
        "    if isinstance(node, DecisionLeafNode):\n",
        "      print(spacing + \"Predict \", node.predictions)\n",
        "      return\n",
        "\n",
        "    print(spacing + str(node.threshold))\n",
        "\n",
        "    print(spacing + '--> True:')\n",
        "    self.print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    print(spacing + '--> False:')\n",
        "    self.print_tree(node.false_branch, spacing + \"  \")\n",
        "\n",
        "\n",
        "  def _mean_of_leaf(self, predictions):\n",
        "    val = 0\n",
        "\n",
        "    for key in predictions.keys():\n",
        "      val = val + key\n",
        "\n",
        "    return val / len(predictions)\n",
        "\n",
        "\n",
        "  def classify(self, test_data, node = None):\n",
        "\n",
        "    if node is None:\n",
        "      node = self.root\n",
        "\n",
        "    if isinstance(node, DecisionLeafNode):\n",
        "      return self._mean_of_leaf(node.predictions)\n",
        "\n",
        "    if node.threshold.match(test_data):\n",
        "      return self.classify(test_data, node.true_branch)\n",
        "    else:\n",
        "      return self.classify(test_data, node.false_branch)\n",
        "\n",
        "\n",
        "\n",
        "class C45Regressor(DecisionTree):\n",
        "\n",
        "  def _split_info(self, true_values, false_values):\n",
        "\n",
        "    split_info = 0\n",
        "\n",
        "    left_ratio = len(true_values) / (len(true_values) + len(false_values))\n",
        "    right_ratio = len(false_values) / (len(true_values) + len(false_values))\n",
        "\n",
        "    split_info -= left_ratio * math.log2(left_ratio)\n",
        "                                   \n",
        "    split_info -= right_ratio * math.log2(right_ratio)\n",
        "\n",
        "    return split_info\n",
        "\n",
        "  def _information_gain(self, true_values, false_values, parent_entropy):\n",
        "    child_weight = float(len(true_values) / (len(true_values) + len(false_values)))\n",
        "\n",
        "    information_gain = parent_entropy - (\n",
        "        child_weight * self._entropy(true_values) + (\n",
        "        1 - child_weight) * self._entropy(false_values))\n",
        "    \n",
        "    split_info = self._split_info(true_values, false_values)\n",
        "\n",
        "    return information_gain / split_info\n",
        "\n"
      ],
      "metadata": {
        "id": "3nregRqlLzEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions "
      ],
      "metadata": {
        "id": "CxUegzjqDOtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Function to calculate error\n",
        "\n",
        "def square_errors(actual,predicted):\n",
        "  square_error = 0\n",
        "\n",
        "  for i in range(len(actual)):\n",
        "    square_error = square_error + ((actual[i][-1] - predicted[i]) ** 2)\n",
        "    \n",
        "  mean_square_error = square_error / len(actual)\n",
        "\n",
        "  root_mean_square_error = math.sqrt(mean_square_error)\n",
        "\n",
        "  return mean_square_error, root_mean_square_error"
      ],
      "metadata": {
        "id": "wwVQz5RFExHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find best max_depth\n",
        "\n",
        "def find_best_depth1(x_train):\n",
        "\n",
        "  least_rmse = 100000000000\n",
        "  best_depth = 100\n",
        "\n",
        "  for depth in range(2, 20):\n",
        "\n",
        "      model = DecisionTree(max_depth = depth)\n",
        "      model.fit(x_train.values.tolist())\n",
        "\n",
        "      # pred_train = model.classify(x_train.values.tolist())\n",
        "      results = []\n",
        "\n",
        "      for row in x_val.values.tolist():\n",
        "        results.append(model.classify(row))\n",
        "\n",
        "      mse_val, rmse_val = square_errors(x_val.values.tolist(), results)\n",
        "\n",
        "      if least_rmse > rmse_val:\n",
        "          least_rmse = rmse_val\n",
        "          best_depth = depth\n",
        "\n",
        "  return best_depth\n",
        "\n",
        "\n",
        "def find_best_depth2(x_train):\n",
        "\n",
        "  least_rmse = 100000000000\n",
        "  best_depth = 100\n",
        "\n",
        "  for depth in range(2, 20):\n",
        "\n",
        "      model = C45Regressor(max_depth = depth)\n",
        "      model.fit(x_train.values.tolist())\n",
        "\n",
        "      # pred_train = model.classify(x_train.values.tolist())\n",
        "      results = []\n",
        "\n",
        "      for row in x_val.values.tolist():\n",
        "        results.append(model.classify(row))\n",
        "\n",
        "      mse_val, rmse_val = square_errors(x_val.values.tolist(), results)\n",
        "\n",
        "      if least_rmse > rmse_val:\n",
        "          least_rmse = rmse_val\n",
        "          best_depth = depth\n",
        "\n",
        "  return best_depth"
      ],
      "metadata": {
        "id": "Q1ruFhEfiB10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Predict mobility from new_cases"
      ],
      "metadata": {
        "id": "IWcezWP9igDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove_outliers(\"new_cases\",df)\n",
        "# df.dropna()"
      ],
      "metadata": {
        "id": "EQsVP87MiTyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  train : used for training\n",
        "# val : used for validation\n",
        "# test : used for testing\n",
        "\n",
        "train_size = 0.7\n",
        "val_size = (1-train_size)/2\n",
        "\n",
        "train, val, test = train_val_test_split(df, train_size, val_size)"
      ],
      "metadata": {
        "id": "ZTXPCb38ilEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[['new_cases', 'retail_and_recreation']]\n",
        "\n",
        "x_val = val[['new_cases', 'retail_and_recreation']]\n",
        "\n",
        "x_test = test[['new_cases', 'retail_and_recreation']]"
      ],
      "metadata": {
        "id": "Ntaz9HvUio2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ZydhQTEFhTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CART\n",
        "\n",
        "decisionTree = DecisionTree(max_depth = find_best_depth1(x_train))\n",
        "decisionTree.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "for row in x_test.values.tolist():\n",
        "    predictions.append(decisionTree.classify(row))\n",
        "mse_val, rmse_val = square_errors(x_test.values.tolist(), predictions)\n",
        "print(mse_val)\n",
        "print(rmse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt4A9Gh3jPDy",
        "outputId": "1063c4cd-1306-47e3-e7a6-54a4167b2488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257.4800729335769\n",
            "16.046185619441676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C4.5\n",
        "\n",
        "c45Regressor = C45Regressor(max_depth = find_best_depth2(x_train))\n",
        "c45Regressor.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "\n",
        "for row in x_test.values.tolist():\n",
        "  predictions.append(c45Regressor.classify(row))\n",
        "\n",
        "mse_val, rmse_val= square_errors(x_test.values.tolist(), predictions)\n",
        "                                    \n",
        "print(mse_val)\n",
        "print(rmse_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzZp78FBMAhv",
        "outputId": "f5d51dfe-3377-4d0e-81a5-0a49b9553144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "457.51844725040195\n",
            "21.38968085901241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Predict new_cases from mobility"
      ],
      "metadata": {
        "id": "MgVXWKJnDDDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  train : used for training\n",
        "# val : used for validation\n",
        "# test : used for testing\n",
        "\n",
        "train_size = 0.7\n",
        "val_size = (1-train_size)/2\n",
        "\n",
        "train, val, test = train_val_test_split(df, train_size, val_size)"
      ],
      "metadata": {
        "id": "E-G4CY1oDIM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[['retail_and_recreation', 'new_cases']]\n",
        "\n",
        "x_val = val[['retail_and_recreation', 'new_cases']]\n",
        "\n",
        "x_test = test[['retail_and_recreation', 'new_cases']]"
      ],
      "metadata": {
        "id": "nkaU0A2kDK2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CART\n",
        "\n",
        "decisionTree = DecisionTree(max_depth = find_best_depth1(x_train))\n",
        "decisionTree.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "for row in x_test.values.tolist():\n",
        "    predictions.append(decisionTree.classify(row))\n",
        "mse_val, rmse_val = square_errors(x_test.values.tolist(), predictions)\n",
        "print(mse_val)\n",
        "print(rmse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg_aWTNTkPWI",
        "outputId": "18960ee7-9521-4f7e-f274-9eb7e85c09fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5493578326.905828\n",
            "74118.67731487003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train.values.tolist()"
      ],
      "metadata": {
        "id": "t20gL4KmFdvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C4.5\n",
        "\n",
        "c45Regressor = C45Regressor(max_depth = find_best_depth2(x_train))\n",
        "c45Regressor.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "\n",
        "for row in x_test.values.tolist():\n",
        "  predictions.append(c45Regressor.classify(row))\n",
        "\n",
        "mse_val, rmse_val= square_errors(x_test.values.tolist(), predictions)\n",
        "                                    \n",
        "print(mse_val)\n",
        "print(rmse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ32JHbGkTMl",
        "outputId": "35d3b046-e689-484f-f810-d8b1236ebfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5421584386.186436\n",
            "73631.40896510426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Using all mobilities to predict new cases"
      ],
      "metadata": {
        "id": "0nz2vyqbkZQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove_outliers(\"grocery_and_pharmacy\",df)\n",
        "# remove_outliers(\"residential\",df)\n",
        "# remove_outliers(\"workplaces\",df)\n",
        "# df.dropna()"
      ],
      "metadata": {
        "id": "NSy_FoRUkh4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  train : used for training\n",
        "# val : used for validation\n",
        "# test : used for testing\n",
        "\n",
        "train_size = 0.7\n",
        "val_size = (1-train_size)/2\n",
        "\n",
        "train, val, test = train_val_test_split(df, train_size, val_size)"
      ],
      "metadata": {
        "id": "5obPQh7mksZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train[[\"retail_and_recreation\",\"grocery_and_pharmacy\",\"residential\",\"transit_stations\",\"parks\",\"workplaces\", \"new_cases\"]]\n",
        "\n",
        "x_val = val[[\"retail_and_recreation\",\"grocery_and_pharmacy\",\"residential\",\"transit_stations\",\"parks\",\"workplaces\", \"new_cases\"]]\n",
        "\n",
        "x_test = test[[\"retail_and_recreation\",\"grocery_and_pharmacy\",\"residential\",\"transit_stations\",\"parks\",\"workplaces\", \"new_cases\"]]\n",
        "\n"
      ],
      "metadata": {
        "id": "IuWk8uxwP9ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CART\n",
        "\n",
        "decisionTree = DecisionTree(max_depth = find_best_depth1(x_train))\n",
        "decisionTree.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "for row in x_test.values.tolist():\n",
        "    predictions.append(decisionTree.classify(row))\n",
        "mse_val, rmse_val = square_errors(x_test.values.tolist(), predictions)\n",
        "print(mse_val)\n",
        "print(rmse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zixe87IgkzfH",
        "outputId": "5075ac9f-eab2-4329-89d9-7c08032ae570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2781715177.4268527\n",
            "52741.967894901805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C4.5\n",
        "\n",
        "c45Regressor = C45Regressor(max_depth = find_best_depth2(x_train))\n",
        "c45Regressor.fit(x_train.values.tolist())\n",
        "predictions = []\n",
        "\n",
        "for row in x_test.values.tolist():\n",
        "  predictions.append(c45Regressor.classify(row))\n",
        "\n",
        "mse_val, rmse_val= square_errors(x_test.values.tolist(), predictions)\n",
        "                                    \n",
        "print(mse_val)\n",
        "print(rmse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHoDf2uDkzfI",
        "outputId": "4f3deb80-038a-43c2-c9e4-da6bd73c7810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5568592658.964429\n",
            "74623.00355094553\n"
          ]
        }
      ]
    }
  ]
}